{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run this notebook directly on Google Colab\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/DaniAffCH/Vessel-Geometric-Transformers/blob/main/main.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "[https://github.com/psf/black] already up to date!\n",
      "[https://github.com/pycqa/isort] already up to date!\n",
      "[https://github.com/PyCQA/flake8] already up to date!\n",
      "[https://github.com/pre-commit/mirrors-mypy] already up to date!\n",
      "pre-commit installed at .git/hooks/pre-commit\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "COLAB_RUNTIME = 'google.colab' in sys.modules\n",
    "if COLAB_RUNTIME:\n",
    "    !git clone https://github.com/DaniAffCH/Vessel-Geometric-Transformers.git\n",
    "    !mv Vessel-Geometric-Transformers/* . \n",
    "    !pip install -q -r requirements.txt\n",
    "else:\n",
    "    !pip install -q -r requirements.txt\n",
    "    !pre-commit autoupdate\n",
    "    !pre-commit install\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import load_config\n",
    "import os\n",
    "from config import DatasetConfig, TrainerConfig, BaselineConfig, GatrConfig\n",
    "\n",
    "config_path = os.path.join(\"config\",\"config.yaml\")\n",
    "\n",
    "config = load_config(config_path)\n",
    "dataset_config: DatasetConfig = config.dataset\n",
    "trainer_config: TrainerConfig = config.trainer\n",
    "baseline_config: BaselineConfig = config.baseline\n",
    "gatr_config: GatrConfig = config.gatr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniaffch/Desktop/Uni/Deep_Learning/Vessel-Geometric-Transformers/.venv/lib/python3.10/site-packages/torch_geometric/data/dataset.py:238: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  if osp.exists(f) and torch.load(f) != _repr(self.pre_transform):\n",
      "/home/daniaffch/Desktop/Uni/Deep_Learning/Vessel-Geometric-Transformers/.venv/lib/python3.10/site-packages/torch_geometric/data/dataset.py:246: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  if osp.exists(f) and torch.load(f) != _repr(self.pre_filter):\n",
      "/home/daniaffch/Uni/Deep_Learning/Vessel-Geometric-Transformers/src/data/dataset.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.data, self.slices = torch.load(self.processed_paths[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 2999\n",
      "Validation size: 599\n",
      "Test size: 401\n",
      "Data(pos=[8397, 3], wss=[8397, 3], pressure=[8397], face=[3, 16790], inlet_index=[214], label=Category.Single)\n"
     ]
    }
   ],
   "source": [
    "from src.data import VesselDataModule\n",
    "\n",
    "\n",
    "data = VesselDataModule(dataset_config)\n",
    "print(f'Train size: {len(data.train_set)}')\n",
    "print(f'Validation size: {len(data.val_set)}')\n",
    "print(f'Test size: {len(data.test_set)}')\n",
    "print(data.train_set[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: analisi dati preliminare. Classi bilanciate? Statistiche sul dataset? Qualche plot figo.\n",
    "\n",
    "# TODO: equivariance check! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0150, -0.1882,  0.0018])\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0150, -0.1882,  0.0018,  1.0000,  0.0000]])\n",
      "\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]])\n",
      "\n",
      "tensor([[133520.2500,      0.0000,      0.0000,  ...,      0.0000,\n",
      "              0.0000,      0.0000],\n",
      "        [133502.0156,      0.0000,      0.0000,  ...,      0.0000,\n",
      "              0.0000,      0.0000],\n",
      "        [133503.4844,      0.0000,      0.0000,  ...,      0.0000,\n",
      "              0.0000,      0.0000],\n",
      "        ...,\n",
      "        [133278.6875,      0.0000,      0.0000,  ...,      0.0000,\n",
      "              0.0000,      0.0000],\n",
      "        [133279.0469,      0.0000,      0.0000,  ...,      0.0000,\n",
      "              0.0000,      0.0000],\n",
      "        [133595.0469,      0.0000,      0.0000,  ...,      0.0000,\n",
      "              0.0000,      0.0000]])\n",
      "\n",
      "tensor([[0.0000e+00, 0.0000e+00, 1.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 1.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 1.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        ...,\n",
      "        [0.0000e+00, 0.0000e+00, 1.6714e+04,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 1.7005e+04,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 1.7006e+04,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "from src.lib import PointGeometricAlgebra, TranslationGeometricAlgebra, ScalarGeometricAlgebra, PlaneGeometricAlgebra\n",
    "\n",
    "print(data.train_set[0].pos[0])\n",
    "print(PointGeometricAlgebra.fromElement(data.train_set[0].pos[0].unsqueeze(0)))\n",
    "print()\n",
    "\n",
    "print(TranslationGeometricAlgebra.fromElement(data.train_set[1].wss)[:, :8])\n",
    "print()\n",
    "\n",
    "print(ScalarGeometricAlgebra.fromElement(data.train_set[0].pressure))\n",
    "print()\n",
    "\n",
    "print(PlaneGeometricAlgebra.fromElement(data.train_set[0].face.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdanieleaffinita2000\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.8 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/daniaffch/Uni/Deep_Learning/Vessel-Geometric-Transformers/wandb/run-20240901_173532-nrfgs7v9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/danieleaffinita2000/Vessel-Geometric-Transformers/runs/nrfgs7v9' target=\"_blank\">sage-wood-91</a></strong> to <a href='https://wandb.ai/danieleaffinita2000/Vessel-Geometric-Transformers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/danieleaffinita2000/Vessel-Geometric-Transformers' target=\"_blank\">https://wandb.ai/danieleaffinita2000/Vessel-Geometric-Transformers</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/danieleaffinita2000/Vessel-Geometric-Transformers/runs/nrfgs7v9' target=\"_blank\">https://wandb.ai/danieleaffinita2000/Vessel-Geometric-Transformers/runs/nrfgs7v9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/daniaffch/Desktop/Uni/Deep_Learning/Vessel-Geometric-Transformers/.venv/lib/python3.10/site-packages/lightning/pytorch/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "/home/daniaffch/Desktop/Uni/Deep_Learning/Vessel-Geometric-Transformers/.venv/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:652: Checkpoint directory /home/daniaffch/Uni/Deep_Learning/Vessel-Geometric-Transformers/ckpt exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name             | Type              | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0  | hsProjection     | EquiLinearLayer   | 172 K  | train\n",
      "1  | backbone         | ModuleList        | 811 K  | train\n",
      "2  | outputProjection | EquiLinearLayer   | 576    | train\n",
      "3  | finalProjection  | Linear            | 65     | train\n",
      "4  | loss_fn          | BCEWithLogitsLoss | 0      | train\n",
      "5  | train_accuracy   | BinaryAccuracy    | 0      | train\n",
      "6  | val_accuracy     | BinaryAccuracy    | 0      | train\n",
      "7  | test_accuracy    | BinaryAccuracy    | 0      | train\n",
      "8  | train_f1         | BinaryF1Score     | 0      | train\n",
      "9  | val_f1           | BinaryF1Score     | 0      | train\n",
      "10 | test_f1          | BinaryF1Score     | 0      | train\n",
      "----------------------------------------------------------------\n",
      "984 K     Trainable params\n",
      "0         Non-trainable params\n",
      "984 K     Total params\n",
      "3.938     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniaffch/Desktop/Uni/Deep_Learning/Vessel-Geometric-Transformers/.venv/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/home/daniaffch/Uni/Deep_Learning/Vessel-Geometric-Transformers/src/lib/geometricAlgebraOperations.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  basis = torch.load(BILIN_PATH)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniaffch/Desktop/Uni/Deep_Learning/Vessel-Geometric-Transformers/.venv/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 750/750 [00:27<00:00, 27.53it/s, v_num=s7v9, val/loss=0.0825, val/acc=0.988, val/f1=0.988, train/loss=0.335, train/acc=0.860, train/f1=0.868]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss improved. New best score: 0.083\n",
      "Epoch 0, global step 750: 'val/loss' reached 0.08253 (best 0.08253), saving model to '/home/daniaffch/Uni/Deep_Learning/Vessel-Geometric-Transformers/ckpt/epoch=0-step=750-v1.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 750/750 [00:25<00:00, 29.38it/s, v_num=s7v9, val/loss=0.0551, val/acc=0.978, val/f1=0.978, train/loss=0.0689, train/acc=0.983, train/f1=0.983]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss improved by 0.027 >= min_delta = 0.001. New best score: 0.055\n",
      "Epoch 1, global step 1500: 'val/loss' reached 0.05507 (best 0.05507), saving model to '/home/daniaffch/Uni/Deep_Learning/Vessel-Geometric-Transformers/ckpt/epoch=1-step=1500.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 750/750 [00:24<00:00, 30.62it/s, v_num=s7v9, val/loss=0.0635, val/acc=0.980, val/f1=0.979, train/loss=0.0544, train/acc=0.989, train/f1=0.989]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 2250: 'val/loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 750/750 [00:24<00:00, 30.90it/s, v_num=s7v9, val/loss=0.031, val/acc=0.995, val/f1=0.995, train/loss=0.0608, train/acc=0.985, train/f1=0.985] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss improved by 0.024 >= min_delta = 0.001. New best score: 0.031\n",
      "Epoch 3, global step 3000: 'val/loss' reached 0.03098 (best 0.03098), saving model to '/home/daniaffch/Uni/Deep_Learning/Vessel-Geometric-Transformers/ckpt/epoch=3-step=3000-v1.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 750/750 [00:24<00:00, 30.92it/s, v_num=s7v9, val/loss=0.0326, val/acc=0.995, val/f1=0.995, train/loss=0.034, train/acc=0.993, train/f1=0.993] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 3750: 'val/loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 750/750 [00:24<00:00, 30.73it/s, v_num=s7v9, val/loss=0.0346, val/acc=0.993, val/f1=0.993, train/loss=0.0329, train/acc=0.991, train/f1=0.991]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 4500: 'val/loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 750/750 [00:24<00:00, 30.72it/s, v_num=s7v9, val/loss=0.0413, val/acc=0.992, val/f1=0.991, train/loss=0.031, train/acc=0.994, train/f1=0.994] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val/loss did not improve in the last 3 records. Best score: 0.031. Signaling Trainer to stop.\n",
      "Epoch 6, global step 5250: 'val/loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 750/750 [00:24<00:00, 30.68it/s, v_num=s7v9, val/loss=0.0413, val/acc=0.992, val/f1=0.991, train/loss=0.031, train/acc=0.994, train/f1=0.994]\n"
     ]
    }
   ],
   "source": [
    "from src.trainer import VesselTrainer\n",
    "from src.models import Gatr\n",
    "\n",
    "trainer = VesselTrainer(trainer_config)\n",
    "\n",
    "\n",
    "model = Gatr(gatr_config)\n",
    "trainer.fit(model, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type               | Params | Mode \n",
      "--------------------------------------------------------------\n",
      "0 | encoder        | TransformerEncoder | 2.2 K  | train\n",
      "1 | embedder       | Linear             | 272    | train\n",
      "2 | projection     | Linear             | 19.2 K | train\n",
      "3 | loss_fn        | BCEWithLogitsLoss  | 0      | train\n",
      "4 | train_accuracy | BinaryAccuracy     | 0      | train\n",
      "5 | val_accuracy   | BinaryAccuracy     | 0      | train\n",
      "6 | test_accuracy  | BinaryAccuracy     | 0      | train\n",
      "7 | train_f1       | BinaryF1Score      | 0      | train\n",
      "8 | val_f1         | BinaryF1Score      | 0      | train\n",
      "9 | test_f1        | BinaryF1Score      | 0      | train\n",
      "--------------------------------------------------------------\n",
      "21.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "21.7 K    Total params\n",
      "0.087     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    }
   ],
   "source": [
    "from src.trainer import VesselTrainer\n",
    "from src.models import BaselineTransformer\n",
    "\n",
    "model = BaselineTransformer(baseline_config)\n",
    "\n",
    "trainer.fit(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at ckpt/last.ckpt\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for BaselineTransformer:\n\tMissing key(s) in state_dict: \"encoder.layers.0.attention.q_proj.weight\", \"encoder.layers.0.attention.q_proj.bias\", \"encoder.layers.0.attention.k_proj.weight\", \"encoder.layers.0.attention.k_proj.bias\", \"encoder.layers.0.attention.v_proj.weight\", \"encoder.layers.0.attention.v_proj.bias\", \"encoder.layers.0.attention.out_proj.weight\", \"encoder.layers.0.attention.out_proj.bias\", \"encoder.layers.0.feedforward.0.weight\", \"encoder.layers.0.feedforward.0.bias\", \"encoder.layers.0.feedforward.2.weight\", \"encoder.layers.0.feedforward.2.bias\", \"encoder.layers.0.norm1.weight\", \"encoder.layers.0.norm1.bias\", \"encoder.layers.0.norm2.weight\", \"encoder.layers.0.norm2.bias\", \"encoder.layers.0.highway1.transform.weight\", \"encoder.layers.0.highway1.transform.bias\", \"encoder.layers.0.highway2.transform.weight\", \"encoder.layers.0.highway2.transform.bias\", \"embedder.weight\", \"embedder.bias\", \"projection.weight\", \"projection.bias\". \n\tUnexpected key(s) in state_dict: \"hsProjection.weights\", \"backbone.0.branch1.1.weights\", \"backbone.0.branch1.2.q_proj.weights\", \"backbone.0.branch1.2.k_proj.weights\", \"backbone.0.branch1.2.v_proj.weights\", \"backbone.0.branch1.2.out_proj.weights\", \"backbone.0.branch1.3.weights\", \"backbone.0.branch2.1.weights\", \"backbone.0.branch2.2.prodX_proj.weights\", \"backbone.0.branch2.2.prodY_proj.weights\", \"backbone.0.branch2.2.joinX_proj.weights\", \"backbone.0.branch2.2.joinY_proj.weights\", \"backbone.0.branch2.2.final_proj.weights\", \"backbone.0.branch2.4.weights\", \"backbone.1.branch1.1.weights\", \"backbone.1.branch1.2.q_proj.weights\", \"backbone.1.branch1.2.k_proj.weights\", \"backbone.1.branch1.2.v_proj.weights\", \"backbone.1.branch1.2.out_proj.weights\", \"backbone.1.branch1.3.weights\", \"backbone.1.branch2.1.weights\", \"backbone.1.branch2.2.prodX_proj.weights\", \"backbone.1.branch2.2.prodY_proj.weights\", \"backbone.1.branch2.2.joinX_proj.weights\", \"backbone.1.branch2.2.joinY_proj.weights\", \"backbone.1.branch2.2.final_proj.weights\", \"backbone.1.branch2.4.weights\", \"outputProjection.weights\", \"finalProjection.weight\", \"finalProjection.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Uni/Deep_Learning/Vessel-Geometric-Transformers/src/trainer/trainer.py:61\u001b[0m, in \u001b[0;36mVesselTrainer.test\u001b[0;34m(self, model, datamodule)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest\u001b[39m(\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28mself\u001b[39m, model: L\u001b[38;5;241m.\u001b[39mLightningModule, datamodule: L\u001b[38;5;241m.\u001b[39mLightningDataModule\n\u001b[1;32m     59\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Test the model on the test set.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatamodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m        \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/last.ckpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Uni/Deep_Learning/Vessel-Geometric-Transformers/.venv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:753\u001b[0m, in \u001b[0;36mTrainer.test\u001b[0;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    752\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtesting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 753\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    754\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_test_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\n\u001b[1;32m    755\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Uni/Deep_Learning/Vessel-Geometric-Transformers/.venv/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/Desktop/Uni/Deep_Learning/Vessel-Geometric-Transformers/.venv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:793\u001b[0m, in \u001b[0;36mTrainer._test_impl\u001b[0;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    790\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn, ckpt_path, model_provided\u001b[38;5;241m=\u001b[39mmodel_provided, model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    792\u001b[0m )\n\u001b[0;32m--> 793\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[38;5;66;03m# remove the tensors from the test results\u001b[39;00m\n\u001b[1;32m    795\u001b[0m results \u001b[38;5;241m=\u001b[39m convert_tensors_to_scalars(results)\n",
      "File \u001b[0;32m~/Desktop/Uni/Deep_Learning/Vessel-Geometric-Transformers/.venv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:955\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mrestore_checkpoint_after_setup:\n\u001b[1;32m    954\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: restoring module and callbacks from checkpoint path: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mckpt_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 955\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_checkpoint_connector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_restore_modules_and_callbacks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;66;03m# reset logger connector\u001b[39;00m\n\u001b[1;32m    958\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger_connector\u001b[38;5;241m.\u001b[39mreset_results()\n",
      "File \u001b[0;32m~/Desktop/Uni/Deep_Learning/Vessel-Geometric-Transformers/.venv/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py:398\u001b[0m, in \u001b[0;36m_CheckpointConnector._restore_modules_and_callbacks\u001b[0;34m(self, checkpoint_path)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_restore_modules_and_callbacks\u001b[39m(\u001b[38;5;28mself\u001b[39m, checkpoint_path: Optional[_PATH] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;66;03m# restore modules after setup\u001b[39;00m\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresume_start(checkpoint_path)\n\u001b[0;32m--> 398\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    399\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrestore_datamodule()\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;241m==\u001b[39m TrainerFn\u001b[38;5;241m.\u001b[39mFITTING:\n\u001b[1;32m    401\u001b[0m         \u001b[38;5;66;03m# restore callback states\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Uni/Deep_Learning/Vessel-Geometric-Transformers/.venv/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py:275\u001b[0m, in \u001b[0;36m_CheckpointConnector.restore_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    272\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_lightning_module_hook(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_load_checkpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loaded_checkpoint)\n\u001b[1;32m    274\u001b[0m \u001b[38;5;66;03m# restore model state_dict\u001b[39;00m\n\u001b[0;32m--> 275\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model_state_dict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_loaded_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrict_loading\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Uni/Deep_Learning/Vessel-Geometric-Transformers/.venv/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py:371\u001b[0m, in \u001b[0;36mStrategy.load_model_state_dict\u001b[0;34m(self, checkpoint, strict)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model_state_dict\u001b[39m(\u001b[38;5;28mself\u001b[39m, checkpoint: Mapping[\u001b[38;5;28mstr\u001b[39m, Any], strict: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 371\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstate_dict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Uni/Deep_Learning/Vessel-Geometric-Transformers/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:2215\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2210\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2211\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2212\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2215\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2216\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2217\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for BaselineTransformer:\n\tMissing key(s) in state_dict: \"encoder.layers.0.attention.q_proj.weight\", \"encoder.layers.0.attention.q_proj.bias\", \"encoder.layers.0.attention.k_proj.weight\", \"encoder.layers.0.attention.k_proj.bias\", \"encoder.layers.0.attention.v_proj.weight\", \"encoder.layers.0.attention.v_proj.bias\", \"encoder.layers.0.attention.out_proj.weight\", \"encoder.layers.0.attention.out_proj.bias\", \"encoder.layers.0.feedforward.0.weight\", \"encoder.layers.0.feedforward.0.bias\", \"encoder.layers.0.feedforward.2.weight\", \"encoder.layers.0.feedforward.2.bias\", \"encoder.layers.0.norm1.weight\", \"encoder.layers.0.norm1.bias\", \"encoder.layers.0.norm2.weight\", \"encoder.layers.0.norm2.bias\", \"encoder.layers.0.highway1.transform.weight\", \"encoder.layers.0.highway1.transform.bias\", \"encoder.layers.0.highway2.transform.weight\", \"encoder.layers.0.highway2.transform.bias\", \"embedder.weight\", \"embedder.bias\", \"projection.weight\", \"projection.bias\". \n\tUnexpected key(s) in state_dict: \"hsProjection.weights\", \"backbone.0.branch1.1.weights\", \"backbone.0.branch1.2.q_proj.weights\", \"backbone.0.branch1.2.k_proj.weights\", \"backbone.0.branch1.2.v_proj.weights\", \"backbone.0.branch1.2.out_proj.weights\", \"backbone.0.branch1.3.weights\", \"backbone.0.branch2.1.weights\", \"backbone.0.branch2.2.prodX_proj.weights\", \"backbone.0.branch2.2.prodY_proj.weights\", \"backbone.0.branch2.2.joinX_proj.weights\", \"backbone.0.branch2.2.joinY_proj.weights\", \"backbone.0.branch2.2.final_proj.weights\", \"backbone.0.branch2.4.weights\", \"backbone.1.branch1.1.weights\", \"backbone.1.branch1.2.q_proj.weights\", \"backbone.1.branch1.2.k_proj.weights\", \"backbone.1.branch1.2.v_proj.weights\", \"backbone.1.branch1.2.out_proj.weights\", \"backbone.1.branch1.3.weights\", \"backbone.1.branch2.1.weights\", \"backbone.1.branch2.2.prodX_proj.weights\", \"backbone.1.branch2.2.prodY_proj.weights\", \"backbone.1.branch2.2.joinX_proj.weights\", \"backbone.1.branch2.2.joinY_proj.weights\", \"backbone.1.branch2.2.final_proj.weights\", \"backbone.1.branch2.4.weights\", \"outputProjection.weights\", \"finalProjection.weight\", \"finalProjection.bias\". "
     ]
    }
   ],
   "source": [
    "trainer.test(model, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
