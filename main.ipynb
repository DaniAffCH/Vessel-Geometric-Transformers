{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run this notebook directly on Google Colab\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/DaniAffCH/Vessel-Geometric-Transformers/blob/main/main.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "[https://github.com/psf/black] already up to date!\n",
      "[https://github.com/pycqa/isort] already up to date!\n",
      "[https://github.com/PyCQA/flake8] already up to date!\n",
      "[https://github.com/pre-commit/mirrors-mypy] already up to date!\n",
      "pre-commit installed at .git/hooks/pre-commit\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "COLAB_RUNTIME = 'google.colab' in sys.modules\n",
    "if COLAB_RUNTIME:\n",
    "    !git clone https://github.com/DaniAffCH/Vessel-Geometric-Transformers.git\n",
    "    !mv Vessel-Geometric-Transformers/* . \n",
    "    !pip install -q -r requirements.txt\n",
    "else:\n",
    "    !pip install -q -r requirements.txt\n",
    "    !pre-commit autoupdate\n",
    "    !pre-commit install\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import load_config\n",
    "import os\n",
    "from config import DatasetConfig, TrainerConfig, BaselineConfig, GatrConfig\n",
    "\n",
    "config_path = os.path.join(\"config\",\"config.yaml\")\n",
    "\n",
    "config = load_config(config_path)\n",
    "dataset_config: DatasetConfig = config.dataset\n",
    "trainer_config: TrainerConfig = config.trainer\n",
    "baseline_config: BaselineConfig = config.baseline\n",
    "gatr_config: GatrConfig = config.gatr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniaffch/Desktop/Uni/Deep_Learning/Vessel-Geometric-Transformers/.venv/lib/python3.10/site-packages/torch_geometric/data/dataset.py:238: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  if osp.exists(f) and torch.load(f) != _repr(self.pre_transform):\n",
      "/home/daniaffch/Desktop/Uni/Deep_Learning/Vessel-Geometric-Transformers/.venv/lib/python3.10/site-packages/torch_geometric/data/dataset.py:246: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  if osp.exists(f) and torch.load(f) != _repr(self.pre_filter):\n",
      "/home/daniaffch/Uni/Deep_Learning/Vessel-Geometric-Transformers/src/data/dataset.py:55: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.data, self.slices = torch.load(self.processed_paths[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 2999\n",
      "Validation size: 599\n",
      "Test size: 401\n",
      "Data(pos=[8397, 3], wss=[8397, 3], pressure=[8397], face=[3, 16790], inlet_index=[214], label=Category.Single)\n"
     ]
    }
   ],
   "source": [
    "from src.data import VesselDataModule\n",
    "\n",
    "\n",
    "data = VesselDataModule(dataset_config)\n",
    "print(f'Train size: {len(data.train_set)}')\n",
    "print(f'Validation size: {len(data.val_set)}')\n",
    "print(f'Test size: {len(data.test_set)}')\n",
    "print(data.train_set[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: analisi dati preliminare. Classi bilanciate? Statistiche sul dataset? Qualche plot figo.\n",
    "\n",
    "# TODO: equivariance check! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdanieleaffinita2000\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.9 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/daniaffch/Uni/Deep_Learning/Vessel-Geometric-Transformers/wandb/run-20240906_174422-k9f4m2or</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/danieleaffinita2000/Vessel-Geometric-Transformers/runs/k9f4m2or' target=\"_blank\">clear-disco-134</a></strong> to <a href='https://wandb.ai/danieleaffinita2000/Vessel-Geometric-Transformers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/danieleaffinita2000/Vessel-Geometric-Transformers' target=\"_blank\">https://wandb.ai/danieleaffinita2000/Vessel-Geometric-Transformers</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/danieleaffinita2000/Vessel-Geometric-Transformers/runs/k9f4m2or' target=\"_blank\">https://wandb.ai/danieleaffinita2000/Vessel-Geometric-Transformers/runs/k9f4m2or</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/daniaffch/Desktop/Uni/Deep_Learning/Vessel-Geometric-Transformers/.venv/lib/python3.10/site-packages/lightning/pytorch/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name            | Type              | Params | Mode \n",
      "--------------------------------------------------------------\n",
      "0 | hsProjection    | EquiLinearLayer   | 576    | train\n",
      "1 | backbone        | ModuleList        | 25.3 K | train\n",
      "2 | finalProjection | Linear            | 76.8 K | train\n",
      "3 | loss_fn         | BCEWithLogitsLoss | 0      | train\n",
      "4 | train_accuracy  | BinaryAccuracy    | 0      | train\n",
      "5 | val_accuracy    | BinaryAccuracy    | 0      | train\n",
      "6 | test_accuracy   | BinaryAccuracy    | 0      | train\n",
      "7 | train_f1        | BinaryF1Score     | 0      | train\n",
      "8 | val_f1          | BinaryF1Score     | 0      | train\n",
      "9 | test_f1         | BinaryF1Score     | 0      | train\n",
      "--------------------------------------------------------------\n",
      "102 K     Trainable params\n",
      "0         Non-trainable params\n",
      "102 K     Total params\n",
      "0.411     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniaffch/Uni/Deep_Learning/Vessel-Geometric-Transformers/src/lib/geometricAlgebraOperations.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  basis = torch.load(BILIN_PATH)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 750/750 [00:14<00:00, 50.24it/s, v_num=m2or, val/loss=0.0556, val/acc=0.987, val/f1=0.986, train/loss=0.172, train/acc=0.942, train/f1=0.941]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss improved. New best score: 0.056\n",
      "Epoch 0, global step 750: 'val/loss' reached 0.05563 (best 0.05563), saving model to '/home/daniaffch/Uni/Deep_Learning/Vessel-Geometric-Transformers/ckpt/epoch=0-step=750.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 750/750 [00:16<00:00, 46.42it/s, v_num=m2or, val/loss=0.0437, val/acc=0.990, val/f1=0.990, train/loss=0.0474, train/acc=0.984, train/f1=0.984]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss improved by 0.012 >= min_delta = 1e-05. New best score: 0.044\n",
      "Epoch 1, global step 1500: 'val/loss' reached 0.04375 (best 0.04375), saving model to '/home/daniaffch/Uni/Deep_Learning/Vessel-Geometric-Transformers/ckpt/epoch=1-step=1500.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 750/750 [00:16<00:00, 44.64it/s, v_num=m2or, val/loss=0.0275, val/acc=0.992, val/f1=0.991, train/loss=0.0375, train/acc=0.988, train/f1=0.988]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss improved by 0.016 >= min_delta = 1e-05. New best score: 0.027\n",
      "Epoch 2, global step 2250: 'val/loss' reached 0.02745 (best 0.02745), saving model to '/home/daniaffch/Uni/Deep_Learning/Vessel-Geometric-Transformers/ckpt/epoch=2-step=2250.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 750/750 [00:16<00:00, 44.29it/s, v_num=m2or, val/loss=0.023, val/acc=0.992, val/f1=0.991, train/loss=0.0336, train/acc=0.989, train/f1=0.989] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss improved by 0.004 >= min_delta = 1e-05. New best score: 0.023\n",
      "Epoch 3, global step 3000: 'val/loss' reached 0.02304 (best 0.02304), saving model to '/home/daniaffch/Uni/Deep_Learning/Vessel-Geometric-Transformers/ckpt/epoch=3-step=3000.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 750/750 [00:17<00:00, 42.73it/s, v_num=m2or, val/loss=0.0166, val/acc=0.993, val/f1=0.993, train/loss=0.0212, train/acc=0.995, train/f1=0.995]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss improved by 0.006 >= min_delta = 1e-05. New best score: 0.017\n",
      "Epoch 4, global step 3750: 'val/loss' reached 0.01661 (best 0.01661), saving model to '/home/daniaffch/Uni/Deep_Learning/Vessel-Geometric-Transformers/ckpt/epoch=4-step=3750.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 750/750 [00:17<00:00, 42.84it/s, v_num=m2or, val/loss=0.00708, val/acc=0.997, val/f1=0.997, train/loss=0.0114, train/acc=0.997, train/f1=0.997]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss improved by 0.010 >= min_delta = 1e-05. New best score: 0.007\n",
      "Epoch 5, global step 4500: 'val/loss' reached 0.00708 (best 0.00708), saving model to '/home/daniaffch/Uni/Deep_Learning/Vessel-Geometric-Transformers/ckpt/epoch=5-step=4500.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 750/750 [00:17<00:00, 42.16it/s, v_num=m2or, val/loss=0.00176, val/acc=1.000, val/f1=1.000, train/loss=0.00274, train/acc=1.000, train/f1=1.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss improved by 0.005 >= min_delta = 1e-05. New best score: 0.002\n",
      "Epoch 6, global step 5250: 'val/loss' reached 0.00176 (best 0.00176), saving model to '/home/daniaffch/Uni/Deep_Learning/Vessel-Geometric-Transformers/ckpt/epoch=6-step=5250.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 750/750 [00:17<00:00, 42.07it/s, v_num=m2or, val/loss=0.000507, val/acc=1.000, val/f1=1.000, train/loss=0.00156, train/acc=0.999, train/f1=0.999]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss improved by 0.001 >= min_delta = 1e-05. New best score: 0.001\n",
      "Epoch 7, global step 6000: 'val/loss' reached 0.00051 (best 0.00051), saving model to '/home/daniaffch/Uni/Deep_Learning/Vessel-Geometric-Transformers/ckpt/epoch=7-step=6000.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 750/750 [00:18<00:00, 41.49it/s, v_num=m2or, val/loss=0.000536, val/acc=1.000, val/f1=1.000, train/loss=0.00346, train/acc=0.999, train/f1=0.999]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 6750: 'val/loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 750/750 [00:17<00:00, 41.76it/s, v_num=m2or, val/loss=0.000248, val/acc=1.000, val/f1=1.000, train/loss=0.000325, train/acc=1.000, train/f1=1.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss improved by 0.000 >= min_delta = 1e-05. New best score: 0.000\n",
      "Epoch 9, global step 7500: 'val/loss' reached 0.00025 (best 0.00025), saving model to '/home/daniaffch/Uni/Deep_Learning/Vessel-Geometric-Transformers/ckpt/epoch=9-step=7500.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 750/750 [00:18<00:00, 41.32it/s, v_num=m2or, val/loss=0.000109, val/acc=1.000, val/f1=1.000, train/loss=6.94e-5, train/acc=1.000, train/f1=1.000] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss improved by 0.000 >= min_delta = 1e-05. New best score: 0.000\n",
      "Epoch 10, global step 8250: 'val/loss' reached 0.00011 (best 0.00011), saving model to '/home/daniaffch/Uni/Deep_Learning/Vessel-Geometric-Transformers/ckpt/epoch=10-step=8250.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 750/750 [00:18<00:00, 41.17it/s, v_num=m2or, val/loss=0.000194, val/acc=1.000, val/f1=1.000, train/loss=4.15e-5, train/acc=1.000, train/f1=1.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, global step 9000: 'val/loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 750/750 [00:18<00:00, 40.42it/s, v_num=m2or, val/loss=4.36e-5, val/acc=1.000, val/f1=1.000, train/loss=3.34e-5, train/acc=1.000, train/f1=1.000] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss improved by 0.000 >= min_delta = 1e-05. New best score: 0.000\n",
      "Epoch 12, global step 9750: 'val/loss' reached 0.00004 (best 0.00004), saving model to '/home/daniaffch/Uni/Deep_Learning/Vessel-Geometric-Transformers/ckpt/epoch=12-step=9750.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 750/750 [00:18<00:00, 40.77it/s, v_num=m2or, val/loss=3.57e-5, val/acc=1.000, val/f1=1.000, train/loss=2.31e-5, train/acc=1.000, train/f1=1.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13, global step 10500: 'val/loss' reached 0.00004 (best 0.00004), saving model to '/home/daniaffch/Uni/Deep_Learning/Vessel-Geometric-Transformers/ckpt/epoch=13-step=10500.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 750/750 [00:18<00:00, 40.82it/s, v_num=m2or, val/loss=2.18e-5, val/acc=1.000, val/f1=1.000, train/loss=1.12e-5, train/acc=1.000, train/f1=1.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss improved by 0.000 >= min_delta = 1e-05. New best score: 0.000\n",
      "Epoch 14, global step 11250: 'val/loss' reached 0.00002 (best 0.00002), saving model to '/home/daniaffch/Uni/Deep_Learning/Vessel-Geometric-Transformers/ckpt/epoch=14-step=11250.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 750/750 [00:18<00:00, 40.37it/s, v_num=m2or, val/loss=2.14e-5, val/acc=1.000, val/f1=1.000, train/loss=8.94e-6, train/acc=1.000, train/f1=1.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15, global step 12000: 'val/loss' reached 0.00002 (best 0.00002), saving model to '/home/daniaffch/Uni/Deep_Learning/Vessel-Geometric-Transformers/ckpt/epoch=15-step=12000.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 750/750 [00:18<00:00, 40.69it/s, v_num=m2or, val/loss=1.05e-5, val/acc=1.000, val/f1=1.000, train/loss=4.47e-6, train/acc=1.000, train/f1=1.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss improved by 0.000 >= min_delta = 1e-05. New best score: 0.000\n",
      "Epoch 16, global step 12750: 'val/loss' reached 0.00001 (best 0.00001), saving model to '/home/daniaffch/Uni/Deep_Learning/Vessel-Geometric-Transformers/ckpt/epoch=16-step=12750.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 750/750 [00:17<00:00, 42.56it/s, v_num=m2or, val/loss=1.82e-5, val/acc=1.000, val/f1=1.000, train/loss=2.81e-6, train/acc=1.000, train/f1=1.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17, global step 13500: 'val/loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 750/750 [00:17<00:00, 41.78it/s, v_num=m2or, val/loss=1.69e-5, val/acc=1.000, val/f1=1.000, train/loss=1.89e-6, train/acc=1.000, train/f1=1.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18, global step 14250: 'val/loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 750/750 [00:17<00:00, 42.79it/s, v_num=m2or, val/loss=4.16e-6, val/acc=1.000, val/f1=1.000, train/loss=1.13e-6, train/acc=1.000, train/f1=1.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val/loss did not improve in the last 3 records. Best score: 0.000. Signaling Trainer to stop.\n",
      "Epoch 19, global step 15000: 'val/loss' reached 0.00000 (best 0.00000), saving model to '/home/daniaffch/Uni/Deep_Learning/Vessel-Geometric-Transformers/ckpt/epoch=19-step=15000.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 750/750 [00:17<00:00, 42.76it/s, v_num=m2or, val/loss=4.16e-6, val/acc=1.000, val/f1=1.000, train/loss=1.13e-6, train/acc=1.000, train/f1=1.000]\n"
     ]
    }
   ],
   "source": [
    "from src.trainer import VesselTrainer\n",
    "from src.models import Gatr\n",
    "\n",
    "trainer = VesselTrainer(trainer_config)\n",
    "\n",
    "\n",
    "model = Gatr(gatr_config)\n",
    "trainer.fit(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /home/daniaffch/Uni/Deep_Learning/Vessel-Geometric-Transformers/ckpt/epoch=19-step=15000.ckpt\n",
      "/home/daniaffch/Desktop/Uni/Deep_Learning/Vessel-Geometric-Transformers/.venv/lib/python3.10/site-packages/lightning/fabric/utilities/cloud_io.py:57: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /home/daniaffch/Uni/Deep_Learning/Vessel-Geometric-Transformers/ckpt/epoch=19-step=15000.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 101/101 [00:00<00:00, 102.20it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test/acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            1.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test/f1          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            1.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test/loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   5.252342452877201e-05   </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test/acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           1.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test/f1         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           1.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test/loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  5.252342452877201e-05  \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.test(model, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:k9f4m2or) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>test/acc</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>train/acc</td><td>▁▆▇▇▇███████████████</td></tr><tr><td>train/f1</td><td>▁▆▇▇▇███████████████</td></tr><tr><td>train/loss</td><td>█▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>val/acc</td><td>▁▃▄▄▅▆██████████████</td></tr><tr><td>val/f1</td><td>▁▃▄▄▅▆██████████████</td></tr><tr><td>val/loss</td><td>█▇▄▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>20</td></tr><tr><td>test/acc</td><td>1.0</td></tr><tr><td>test/f1</td><td>1.0</td></tr><tr><td>test/loss</td><td>5e-05</td></tr><tr><td>train/acc</td><td>1.0</td></tr><tr><td>train/f1</td><td>1.0</td></tr><tr><td>train/loss</td><td>0.0</td></tr><tr><td>trainer/global_step</td><td>15000</td></tr><tr><td>val/acc</td><td>1.0</td></tr><tr><td>val/f1</td><td>1.0</td></tr><tr><td>val/loss</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">clear-disco-134</strong> at: <a href='https://wandb.ai/danieleaffinita2000/Vessel-Geometric-Transformers/runs/k9f4m2or' target=\"_blank\">https://wandb.ai/danieleaffinita2000/Vessel-Geometric-Transformers/runs/k9f4m2or</a><br/> View project at: <a href='https://wandb.ai/danieleaffinita2000/Vessel-Geometric-Transformers' target=\"_blank\">https://wandb.ai/danieleaffinita2000/Vessel-Geometric-Transformers</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240906_174422-k9f4m2or/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:k9f4m2or). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.9 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/daniaffch/Uni/Deep_Learning/Vessel-Geometric-Transformers/wandb/run-20240906_175021-9nc0pdr5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/danieleaffinita2000/Vessel-Geometric-Transformers/runs/9nc0pdr5' target=\"_blank\">woven-aardvark-135</a></strong> to <a href='https://wandb.ai/danieleaffinita2000/Vessel-Geometric-Transformers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/danieleaffinita2000/Vessel-Geometric-Transformers' target=\"_blank\">https://wandb.ai/danieleaffinita2000/Vessel-Geometric-Transformers</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/danieleaffinita2000/Vessel-Geometric-Transformers/runs/9nc0pdr5' target=\"_blank\">https://wandb.ai/danieleaffinita2000/Vessel-Geometric-Transformers/runs/9nc0pdr5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/daniaffch/Desktop/Uni/Deep_Learning/Vessel-Geometric-Transformers/.venv/lib/python3.10/site-packages/lightning/pytorch/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "/home/daniaffch/Desktop/Uni/Deep_Learning/Vessel-Geometric-Transformers/.venv/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:652: Checkpoint directory /home/daniaffch/Uni/Deep_Learning/Vessel-Geometric-Transformers/ckpt exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type               | Params | Mode \n",
      "--------------------------------------------------------------\n",
      "0 | encoder        | TransformerEncoder | 2.2 K  | train\n",
      "1 | embedder       | Linear             | 272    | train\n",
      "2 | projection     | Linear             | 19.2 K | train\n",
      "3 | loss_fn        | BCEWithLogitsLoss  | 0      | train\n",
      "4 | train_accuracy | BinaryAccuracy     | 0      | train\n",
      "5 | val_accuracy   | BinaryAccuracy     | 0      | train\n",
      "6 | test_accuracy  | BinaryAccuracy     | 0      | train\n",
      "7 | train_f1       | BinaryF1Score      | 0      | train\n",
      "8 | val_f1         | BinaryF1Score      | 0      | train\n",
      "9 | test_f1        | BinaryF1Score      | 0      | train\n",
      "--------------------------------------------------------------\n",
      "21.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "21.7 K    Total params\n",
      "0.087     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 750/750 [00:18<00:00, 39.70it/s, v_num=pdr5, val/loss=0.0518, val/acc=0.987, val/f1=0.986, train/loss=0.194, train/acc=0.921, train/f1=0.922]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss improved. New best score: 0.052\n",
      "Epoch 0, global step 750: 'val/loss' reached 0.05180 (best 0.05180), saving model to '/home/daniaffch/Uni/Deep_Learning/Vessel-Geometric-Transformers/ckpt/epoch=0-step=750.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 750/750 [00:20<00:00, 37.20it/s, v_num=pdr5, val/loss=0.0438, val/acc=0.988, val/f1=0.988, train/loss=0.0576, train/acc=0.981, train/f1=0.982]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss improved by 0.008 >= min_delta = 1e-05. New best score: 0.044\n",
      "Epoch 1, global step 1500: 'val/loss' reached 0.04383 (best 0.04383), saving model to '/home/daniaffch/Uni/Deep_Learning/Vessel-Geometric-Transformers/ckpt/epoch=1-step=1500.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 750/750 [00:20<00:00, 37.36it/s, v_num=pdr5, val/loss=0.0553, val/acc=0.977, val/f1=0.976, train/loss=0.0372, train/acc=0.988, train/f1=0.988]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 2250: 'val/loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 750/750 [00:19<00:00, 37.51it/s, v_num=pdr5, val/loss=0.00806, val/acc=0.997, val/f1=0.997, train/loss=0.0167, train/acc=0.994, train/f1=0.994]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss improved by 0.036 >= min_delta = 1e-05. New best score: 0.008\n",
      "Epoch 3, global step 3000: 'val/loss' reached 0.00806 (best 0.00806), saving model to '/home/daniaffch/Uni/Deep_Learning/Vessel-Geometric-Transformers/ckpt/epoch=3-step=3000.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 750/750 [00:20<00:00, 37.39it/s, v_num=pdr5, val/loss=0.0104, val/acc=0.997, val/f1=0.997, train/loss=0.00523, train/acc=0.999, train/f1=0.999]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 3750: 'val/loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 750/750 [00:20<00:00, 37.39it/s, v_num=pdr5, val/loss=0.00832, val/acc=0.997, val/f1=0.997, train/loss=0.0835, train/acc=0.989, train/f1=0.989] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 4500: 'val/loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 750/750 [00:20<00:00, 36.92it/s, v_num=pdr5, val/loss=0.00549, val/acc=0.997, val/f1=0.997, train/loss=0.00281, train/acc=1.000, train/f1=1.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss improved by 0.003 >= min_delta = 1e-05. New best score: 0.005\n",
      "Epoch 6, global step 5250: 'val/loss' reached 0.00549 (best 0.00549), saving model to '/home/daniaffch/Uni/Deep_Learning/Vessel-Geometric-Transformers/ckpt/epoch=6-step=5250.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 750/750 [00:20<00:00, 37.34it/s, v_num=pdr5, val/loss=0.0054, val/acc=0.997, val/f1=0.997, train/loss=0.00162, train/acc=1.000, train/f1=1.000] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss improved by 0.000 >= min_delta = 1e-05. New best score: 0.005\n",
      "Epoch 7, global step 6000: 'val/loss' reached 0.00540 (best 0.00540), saving model to '/home/daniaffch/Uni/Deep_Learning/Vessel-Geometric-Transformers/ckpt/epoch=7-step=6000.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 750/750 [00:20<00:00, 37.35it/s, v_num=pdr5, val/loss=0.00614, val/acc=0.997, val/f1=0.997, train/loss=0.000695, train/acc=1.000, train/f1=1.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 6750: 'val/loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 750/750 [00:20<00:00, 37.35it/s, v_num=pdr5, val/loss=0.0143, val/acc=0.995, val/f1=0.995, train/loss=0.000889, train/acc=1.000, train/f1=1.000] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 7500: 'val/loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 750/750 [00:21<00:00, 35.55it/s, v_num=pdr5, val/loss=0.0173, val/acc=0.997, val/f1=0.997, train/loss=0.029, train/acc=0.994, train/f1=0.994]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val/loss did not improve in the last 3 records. Best score: 0.005. Signaling Trainer to stop.\n",
      "Epoch 10, global step 8250: 'val/loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 750/750 [00:21<00:00, 35.54it/s, v_num=pdr5, val/loss=0.0173, val/acc=0.997, val/f1=0.997, train/loss=0.029, train/acc=0.994, train/f1=0.994]\n"
     ]
    }
   ],
   "source": [
    "from src.trainer import VesselTrainer\n",
    "from src.models import BaselineTransformer\n",
    "\n",
    "trainer = VesselTrainer(trainer_config)\n",
    "\n",
    "model = BaselineTransformer(baseline_config)\n",
    "\n",
    "trainer.fit(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /home/daniaffch/Uni/Deep_Learning/Vessel-Geometric-Transformers/ckpt/epoch=7-step=6000.ckpt\n",
      "/home/daniaffch/Desktop/Uni/Deep_Learning/Vessel-Geometric-Transformers/.venv/lib/python3.10/site-packages/lightning/fabric/utilities/cloud_io.py:57: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /home/daniaffch/Uni/Deep_Learning/Vessel-Geometric-Transformers/ckpt/epoch=7-step=6000.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 101/101 [00:01<00:00, 72.35it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test/acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9975062608718872     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test/f1          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.997481107711792     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test/loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.010633878409862518    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test/acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9975062608718872    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test/f1         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.997481107711792    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test/loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.010633878409862518   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.test(model, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
