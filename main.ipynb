{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run this notebook directly on Google Colab\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/DaniAffCH/Vessel-Geometric-Transformers/blob/main/main.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "[https://github.com/psf/black] already up to date!\n",
      "[https://github.com/pycqa/isort] already up to date!\n",
      "[https://github.com/PyCQA/flake8] already up to date!\n",
      "[https://github.com/pre-commit/mirrors-mypy] already up to date!\n",
      "pre-commit installed at .git/hooks/pre-commit\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "COLAB_RUNTIME = 'google.colab' in sys.modules\n",
    "if COLAB_RUNTIME:\n",
    "    !git clone https://github.com/DaniAffCH/Vessel-Geometric-Transformers.git\n",
    "    !mv Vessel-Geometric-Transformers/* . \n",
    "    !pip install -q -r requirements.txt\n",
    "else:\n",
    "    !pip install -q -r requirements.txt\n",
    "    !pre-commit autoupdate\n",
    "    !pre-commit install\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import load_config\n",
    "import os\n",
    "from config import DatasetConfig, TrainerConfig, BaselineConfig, GatrConfig\n",
    "\n",
    "config_path = os.path.join(\"config\",\"config.yaml\")\n",
    "\n",
    "config = load_config(config_path)\n",
    "dataset_config: DatasetConfig = config.dataset\n",
    "trainer_config: TrainerConfig = config.trainer\n",
    "baseline_config: BaselineConfig = config.baseline\n",
    "gatr_config: GatrConfig = config.gatr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniaffch/Desktop/Uni/Deep_Learning/Vessel-Geometric-Transformers/.venv/lib/python3.10/site-packages/torch_geometric/data/dataset.py:238: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  if osp.exists(f) and torch.load(f) != _repr(self.pre_transform):\n",
      "/home/daniaffch/Desktop/Uni/Deep_Learning/Vessel-Geometric-Transformers/.venv/lib/python3.10/site-packages/torch_geometric/data/dataset.py:246: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  if osp.exists(f) and torch.load(f) != _repr(self.pre_filter):\n",
      "/home/daniaffch/Uni/Deep_Learning/Vessel-Geometric-Transformers/src/data/dataset.py:55: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.data, self.slices = torch.load(self.processed_paths[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 2999\n",
      "Validation size: 599\n",
      "Test size: 401\n",
      "Data(pos=[8397, 3], wss=[8397, 3], pressure=[8397], face=[3, 16790], inlet_index=[214], label=Category.Single)\n"
     ]
    }
   ],
   "source": [
    "from src.data import VesselDataModule\n",
    "\n",
    "\n",
    "data = VesselDataModule(dataset_config)\n",
    "print(f'Train size: {len(data.train_set)}')\n",
    "print(f'Validation size: {len(data.val_set)}')\n",
    "print(f'Test size: {len(data.test_set)}')\n",
    "print(data.train_set[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='count'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.countplot(data.data.label)\n",
    "\n",
    "# TODO continua data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing equivariance check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniaffch/Desktop/Uni/Deep_Learning/Vessel-Geometric-Transformers/.venv/lib/python3.10/site-packages/numba/np/ufunc/parallel.py:371: NumbaWarning: The TBB threading layer requires TBB version 2021 update 6 or later i.e., TBB_INTERFACE_VERSION >= 12060. Found TBB_INTERFACE_VERSION = 12050. The TBB threading layer is disabled.\n",
      "  warnings.warn(problem)\n",
      "/home/daniaffch/Desktop/Uni/Deep_Learning/Vessel-Geometric-Transformers/.venv/lib/python3.10/site-packages/numba/core/decorators.py:262: NumbaDeprecationWarning: numba.generated_jit is deprecated. Please see the documentation at: https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-generated-jit for more information and advice on a suitable replacement.\n",
      "  warnings.warn(msg, NumbaDeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ GeometricBilinearLayer passed all equivariance tests.                  [10 inputs, 100 checks each]\n",
      "\n",
      "✅ EquiLinearLayer passed all equivariance tests.                  [10 inputs, 100 checks each]\n",
      "\n",
      "✅ EquiNormLayer passed all equivariance tests.                  [10 inputs, 100 checks each]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "FAIL: test_geomattention_layer (src.test.test_equivariance.TestEquivariance)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/daniaffch/Uni/Deep_Learning/Vessel-Geometric-Transformers/src/test/test_equivariance.py\", line 106, in test_geomattention_layer\n",
      "    self.assertTrue(\n",
      "AssertionError: False is not true : GeometricAttentionLayer failed the equivariance                     test for input 1\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 5.692s\n",
      "\n",
      "FAILED (failures=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ GatedGELU passed all equivariance tests.                  [10 inputs, 100 checks each]\n"
     ]
    }
   ],
   "source": [
    "from src.lib.geometricAlgebraElements import GeometricAlgebraBase\n",
    "from src.test.test_equivariance import TestEquivariance\n",
    "import unittest\n",
    "\n",
    "dl = data.train_dataloader()\n",
    "\n",
    "batch = next(iter(dl)).data[0]\n",
    "batch = batch.view(-1, GeometricAlgebraBase.GA_size)[:10]\n",
    "\n",
    "TestEquivariance.INPUT_DATA = batch\n",
    "\n",
    "suite = unittest.TestSuite()\n",
    "\n",
    "suite.addTests(unittest.TestLoader().loadTestsFromTestCase(TestEquivariance))\n",
    "\n",
    "test_runner = unittest.TextTestRunner(verbosity=0)\n",
    "\n",
    "restResult = test_runner.run(suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: analisi dati preliminare. Classi bilanciate? Statistiche sul dataset? Qualche plot figo.\n",
    "\n",
    "# TODO: HPO\n",
    "\n",
    "# TODO: Analisi risultati!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniaffch/Desktop/Uni/Deep_Learning/Vessel-Geometric-Transformers/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'VesselDataModule' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Gatr\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m partial\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobjective\u001b[39m(trial: optuna\u001b[38;5;241m.\u001b[39mtrial\u001b[38;5;241m.\u001b[39mTrial, data: \u001b[43mVesselDataModule\u001b[49m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# We optimize the number of layers, hidden units in each layer and dropouts.\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     n_layers \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39msuggest_int(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_layers\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m      9\u001b[0m     dropout \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39msuggest_float(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0.2\u001b[39m, \u001b[38;5;241m0.5\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'VesselDataModule' is not defined"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from src.trainer import VesselTrainer\n",
    "from src.models import Gatr\n",
    "from functools import partial\n",
    "\n",
    "def objective(trial: optuna.trial.Trial, data: VesselDataModule) -> float:\n",
    "    # We optimize the number of layers, hidden units in each layer and dropouts.\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.2, 0.5)\n",
    "    output_dims = [\n",
    "        trial.suggest_int(\"n_units_l{}\".format(i), 4, 128, log=True) for i in range(n_layers)\n",
    "    ]\n",
    "\n",
    "    model = Gatr(gatr_config)\n",
    "    trainer = VesselTrainer(trainer_config)\n",
    "\n",
    "    hyperparameters = dict(n_layers=n_layers, dropout=dropout, output_dims=output_dims)\n",
    "    trainer.logger.log_hyperparams(hyperparameters)\n",
    "    trainer.fit(model, datamodule=data)\n",
    "\n",
    "    return trainer.callback_metrics[\"val_acc\"].item()\n",
    "\n",
    "pruner = optuna.pruners.NopPruner()\n",
    "study = optuna.create_study(direction=\"maximize\", pruner=pruner)\n",
    "objective = partial(objective, data = data)\n",
    "study.optimize(objective, n_trials=100, timeout=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdanieleaffinita2000\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.9 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/daniaffch/Uni/Deep_Learning/Vessel-Geometric-Transformers/wandb/run-20240911_195731-q97v8hmp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/danieleaffinita2000/Vessel-Geometric-Transformers/runs/q97v8hmp' target=\"_blank\">flowing-dragon-138</a></strong> to <a href='https://wandb.ai/danieleaffinita2000/Vessel-Geometric-Transformers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/danieleaffinita2000/Vessel-Geometric-Transformers' target=\"_blank\">https://wandb.ai/danieleaffinita2000/Vessel-Geometric-Transformers</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/danieleaffinita2000/Vessel-Geometric-Transformers/runs/q97v8hmp' target=\"_blank\">https://wandb.ai/danieleaffinita2000/Vessel-Geometric-Transformers/runs/q97v8hmp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/daniaffch/Desktop/Uni/Deep_Learning/Vessel-Geometric-Transformers/.venv/lib/python3.10/site-packages/lightning/pytorch/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "/home/daniaffch/Desktop/Uni/Deep_Learning/Vessel-Geometric-Transformers/.venv/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:652: Checkpoint directory /home/daniaffch/Uni/Deep_Learning/Vessel-Geometric-Transformers/ckpt exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name            | Type              | Params | Mode \n",
      "--------------------------------------------------------------\n",
      "0 | hsProjection    | EquiLinearLayer   | 576    | train\n",
      "1 | backbone        | ModuleList        | 25.3 K | train\n",
      "2 | finalProjection | Linear            | 76.8 K | train\n",
      "3 | loss_fn         | BCEWithLogitsLoss | 0      | train\n",
      "4 | train_accuracy  | BinaryAccuracy    | 0      | train\n",
      "5 | val_accuracy    | BinaryAccuracy    | 0      | train\n",
      "6 | test_accuracy   | BinaryAccuracy    | 0      | train\n",
      "7 | train_f1        | BinaryF1Score     | 0      | train\n",
      "8 | val_f1          | BinaryF1Score     | 0      | train\n",
      "9 | test_f1         | BinaryF1Score     | 0      | train\n",
      "--------------------------------------------------------------\n",
      "102 K     Trainable params\n",
      "0         Non-trainable params\n",
      "102 K     Total params\n",
      "0.411     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  49%|████▉     | 370/750 [00:09<00:09, 40.72it/s, v_num=8hmp]     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniaffch/Desktop/Uni/Deep_Learning/Vessel-Geometric-Transformers/.venv/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "trainer = VesselTrainer(trainer_config)\n",
    "model = Gatr(gatr_config)\n",
    "trainer.fit(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /home/daniaffch/Uni/Deep_Learning/Vessel-Geometric-Transformers/ckpt/epoch=19-step=15000.ckpt\n",
      "/home/daniaffch/Desktop/Uni/Deep_Learning/Vessel-Geometric-Transformers/.venv/lib/python3.10/site-packages/lightning/fabric/utilities/cloud_io.py:57: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /home/daniaffch/Uni/Deep_Learning/Vessel-Geometric-Transformers/ckpt/epoch=19-step=15000.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 101/101 [00:00<00:00, 102.20it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test/acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            1.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test/f1          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            1.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test/loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   5.252342452877201e-05   </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test/acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           1.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test/f1         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           1.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test/loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  5.252342452877201e-05  \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.test(model, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:k9f4m2or) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>test/acc</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>train/acc</td><td>▁▆▇▇▇███████████████</td></tr><tr><td>train/f1</td><td>▁▆▇▇▇███████████████</td></tr><tr><td>train/loss</td><td>█▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>val/acc</td><td>▁▃▄▄▅▆██████████████</td></tr><tr><td>val/f1</td><td>▁▃▄▄▅▆██████████████</td></tr><tr><td>val/loss</td><td>█▇▄▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>20</td></tr><tr><td>test/acc</td><td>1.0</td></tr><tr><td>test/f1</td><td>1.0</td></tr><tr><td>test/loss</td><td>5e-05</td></tr><tr><td>train/acc</td><td>1.0</td></tr><tr><td>train/f1</td><td>1.0</td></tr><tr><td>train/loss</td><td>0.0</td></tr><tr><td>trainer/global_step</td><td>15000</td></tr><tr><td>val/acc</td><td>1.0</td></tr><tr><td>val/f1</td><td>1.0</td></tr><tr><td>val/loss</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">clear-disco-134</strong> at: <a href='https://wandb.ai/danieleaffinita2000/Vessel-Geometric-Transformers/runs/k9f4m2or' target=\"_blank\">https://wandb.ai/danieleaffinita2000/Vessel-Geometric-Transformers/runs/k9f4m2or</a><br/> View project at: <a href='https://wandb.ai/danieleaffinita2000/Vessel-Geometric-Transformers' target=\"_blank\">https://wandb.ai/danieleaffinita2000/Vessel-Geometric-Transformers</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240906_174422-k9f4m2or/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:k9f4m2or). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.9 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/daniaffch/Uni/Deep_Learning/Vessel-Geometric-Transformers/wandb/run-20240906_175021-9nc0pdr5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/danieleaffinita2000/Vessel-Geometric-Transformers/runs/9nc0pdr5' target=\"_blank\">woven-aardvark-135</a></strong> to <a href='https://wandb.ai/danieleaffinita2000/Vessel-Geometric-Transformers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/danieleaffinita2000/Vessel-Geometric-Transformers' target=\"_blank\">https://wandb.ai/danieleaffinita2000/Vessel-Geometric-Transformers</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/danieleaffinita2000/Vessel-Geometric-Transformers/runs/9nc0pdr5' target=\"_blank\">https://wandb.ai/danieleaffinita2000/Vessel-Geometric-Transformers/runs/9nc0pdr5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/daniaffch/Desktop/Uni/Deep_Learning/Vessel-Geometric-Transformers/.venv/lib/python3.10/site-packages/lightning/pytorch/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "/home/daniaffch/Desktop/Uni/Deep_Learning/Vessel-Geometric-Transformers/.venv/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:652: Checkpoint directory /home/daniaffch/Uni/Deep_Learning/Vessel-Geometric-Transformers/ckpt exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type               | Params | Mode \n",
      "--------------------------------------------------------------\n",
      "0 | encoder        | TransformerEncoder | 2.2 K  | train\n",
      "1 | embedder       | Linear             | 272    | train\n",
      "2 | projection     | Linear             | 19.2 K | train\n",
      "3 | loss_fn        | BCEWithLogitsLoss  | 0      | train\n",
      "4 | train_accuracy | BinaryAccuracy     | 0      | train\n",
      "5 | val_accuracy   | BinaryAccuracy     | 0      | train\n",
      "6 | test_accuracy  | BinaryAccuracy     | 0      | train\n",
      "7 | train_f1       | BinaryF1Score      | 0      | train\n",
      "8 | val_f1         | BinaryF1Score      | 0      | train\n",
      "9 | test_f1        | BinaryF1Score      | 0      | train\n",
      "--------------------------------------------------------------\n",
      "21.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "21.7 K    Total params\n",
      "0.087     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 750/750 [00:18<00:00, 39.70it/s, v_num=pdr5, val/loss=0.0518, val/acc=0.987, val/f1=0.986, train/loss=0.194, train/acc=0.921, train/f1=0.922]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss improved. New best score: 0.052\n",
      "Epoch 0, global step 750: 'val/loss' reached 0.05180 (best 0.05180), saving model to '/home/daniaffch/Uni/Deep_Learning/Vessel-Geometric-Transformers/ckpt/epoch=0-step=750.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 750/750 [00:20<00:00, 37.20it/s, v_num=pdr5, val/loss=0.0438, val/acc=0.988, val/f1=0.988, train/loss=0.0576, train/acc=0.981, train/f1=0.982]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss improved by 0.008 >= min_delta = 1e-05. New best score: 0.044\n",
      "Epoch 1, global step 1500: 'val/loss' reached 0.04383 (best 0.04383), saving model to '/home/daniaffch/Uni/Deep_Learning/Vessel-Geometric-Transformers/ckpt/epoch=1-step=1500.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 750/750 [00:20<00:00, 37.36it/s, v_num=pdr5, val/loss=0.0553, val/acc=0.977, val/f1=0.976, train/loss=0.0372, train/acc=0.988, train/f1=0.988]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 2250: 'val/loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 750/750 [00:19<00:00, 37.51it/s, v_num=pdr5, val/loss=0.00806, val/acc=0.997, val/f1=0.997, train/loss=0.0167, train/acc=0.994, train/f1=0.994]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss improved by 0.036 >= min_delta = 1e-05. New best score: 0.008\n",
      "Epoch 3, global step 3000: 'val/loss' reached 0.00806 (best 0.00806), saving model to '/home/daniaffch/Uni/Deep_Learning/Vessel-Geometric-Transformers/ckpt/epoch=3-step=3000.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 750/750 [00:20<00:00, 37.39it/s, v_num=pdr5, val/loss=0.0104, val/acc=0.997, val/f1=0.997, train/loss=0.00523, train/acc=0.999, train/f1=0.999]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 3750: 'val/loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 750/750 [00:20<00:00, 37.39it/s, v_num=pdr5, val/loss=0.00832, val/acc=0.997, val/f1=0.997, train/loss=0.0835, train/acc=0.989, train/f1=0.989] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 4500: 'val/loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 750/750 [00:20<00:00, 36.92it/s, v_num=pdr5, val/loss=0.00549, val/acc=0.997, val/f1=0.997, train/loss=0.00281, train/acc=1.000, train/f1=1.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss improved by 0.003 >= min_delta = 1e-05. New best score: 0.005\n",
      "Epoch 6, global step 5250: 'val/loss' reached 0.00549 (best 0.00549), saving model to '/home/daniaffch/Uni/Deep_Learning/Vessel-Geometric-Transformers/ckpt/epoch=6-step=5250.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 750/750 [00:20<00:00, 37.34it/s, v_num=pdr5, val/loss=0.0054, val/acc=0.997, val/f1=0.997, train/loss=0.00162, train/acc=1.000, train/f1=1.000] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss improved by 0.000 >= min_delta = 1e-05. New best score: 0.005\n",
      "Epoch 7, global step 6000: 'val/loss' reached 0.00540 (best 0.00540), saving model to '/home/daniaffch/Uni/Deep_Learning/Vessel-Geometric-Transformers/ckpt/epoch=7-step=6000.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 750/750 [00:20<00:00, 37.35it/s, v_num=pdr5, val/loss=0.00614, val/acc=0.997, val/f1=0.997, train/loss=0.000695, train/acc=1.000, train/f1=1.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 6750: 'val/loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 750/750 [00:20<00:00, 37.35it/s, v_num=pdr5, val/loss=0.0143, val/acc=0.995, val/f1=0.995, train/loss=0.000889, train/acc=1.000, train/f1=1.000] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 7500: 'val/loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 750/750 [00:21<00:00, 35.55it/s, v_num=pdr5, val/loss=0.0173, val/acc=0.997, val/f1=0.997, train/loss=0.029, train/acc=0.994, train/f1=0.994]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val/loss did not improve in the last 3 records. Best score: 0.005. Signaling Trainer to stop.\n",
      "Epoch 10, global step 8250: 'val/loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 750/750 [00:21<00:00, 35.54it/s, v_num=pdr5, val/loss=0.0173, val/acc=0.997, val/f1=0.997, train/loss=0.029, train/acc=0.994, train/f1=0.994]\n"
     ]
    }
   ],
   "source": [
    "from src.trainer import VesselTrainer\n",
    "from src.models import BaselineTransformer\n",
    "\n",
    "trainer = VesselTrainer(trainer_config)\n",
    "\n",
    "model = BaselineTransformer(baseline_config)\n",
    "\n",
    "trainer.fit(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /home/daniaffch/Uni/Deep_Learning/Vessel-Geometric-Transformers/ckpt/epoch=7-step=6000.ckpt\n",
      "/home/daniaffch/Desktop/Uni/Deep_Learning/Vessel-Geometric-Transformers/.venv/lib/python3.10/site-packages/lightning/fabric/utilities/cloud_io.py:57: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /home/daniaffch/Uni/Deep_Learning/Vessel-Geometric-Transformers/ckpt/epoch=7-step=6000.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 101/101 [00:01<00:00, 72.35it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test/acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9975062608718872     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test/f1          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.997481107711792     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test/loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.010633878409862518    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test/acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9975062608718872    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test/f1         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.997481107711792    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test/loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.010633878409862518   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.test(model, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
