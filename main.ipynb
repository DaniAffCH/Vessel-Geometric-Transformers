{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run this notebook directly on Google Colab\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/DaniAffCH/Vessel-Geometric-Transformers/blob/main/main.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[https://github.com/psf/black] already up to date!\n",
      "[https://github.com/pycqa/isort] already up to date!\n",
      "[https://github.com/PyCQA/flake8] already up to date!\n",
      "[https://github.com/pre-commit/mirrors-mypy] already up to date!\n",
      "pre-commit installed at .git/hooks/pre-commit\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "COLAB_RUNTIME = 'google.colab' in sys.modules\n",
    "if COLAB_RUNTIME:\n",
    "    !git clone https://github.com/DaniAffCH/Vessel-Geometric-Transformers.git\n",
    "    !mv Vessel-Geometric-Transformers/* . \n",
    "    !pip install -q -r requirements.txt\n",
    "else:\n",
    "    !pip install -q -r requirements.txt\n",
    "    !pre-commit autoupdate\n",
    "    !pre-commit install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import load_config\n",
    "import os\n",
    "from config import DatasetConfig, TrainerConfig, BaselineConfig\n",
    "\n",
    "config_path = os.path.join(\"config\",\"config.yaml\")\n",
    "\n",
    "config = load_config(config_path)\n",
    "dataset_config: DatasetConfig = config.dataset\n",
    "trainer_config: TrainerConfig = config.trainer\n",
    "baseline_config: BaselineConfig = config.baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 2999\n",
      "Validation size: 599\n",
      "Test size: 401\n",
      "Data(pos=[19217, 3], wss=[19217, 3], pressure=[19217], face=[3, 38430], inlet_index=[921])\n"
     ]
    }
   ],
   "source": [
    "from src.data import VesselDataModule\n",
    "\n",
    "data = VesselDataModule(dataset_config)\n",
    "print(f'Train size: {len(data.train_set)}')\n",
    "print(f'Validation size: {len(data.val_set)}')\n",
    "print(f'Test size: {len(data.test_set)}')\n",
    "print(data.train_set[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1435, -0.1550, -0.0041])\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000, -0.1435, -0.1550, -0.0041,  1.0000,  0.0000]])\n",
      "\n",
      "tensor([[ 1.0000,  0.0000,  0.0000,  ..., -1.3098, -3.7878, -0.7568],\n",
      "        [ 1.0000,  0.0000,  0.0000,  ..., -1.3070, -3.7272, -0.7964],\n",
      "        [ 1.0000,  0.0000,  0.0000,  ..., -1.2395, -3.6962, -0.8062],\n",
      "        ...,\n",
      "        [ 1.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n",
      "\n",
      "tensor([[133372.5312,      0.0000,      0.0000,  ...,      0.0000,\n",
      "              0.0000,      0.0000],\n",
      "        [133347.1875,      0.0000,      0.0000,  ...,      0.0000,\n",
      "              0.0000,      0.0000],\n",
      "        [133348.7500,      0.0000,      0.0000,  ...,      0.0000,\n",
      "              0.0000,      0.0000],\n",
      "        ...,\n",
      "        [133410.9688,      0.0000,      0.0000,  ...,      0.0000,\n",
      "              0.0000,      0.0000],\n",
      "        [133477.3438,      0.0000,      0.0000,  ...,      0.0000,\n",
      "              0.0000,      0.0000],\n",
      "        [133414.0469,      0.0000,      0.0000,  ...,      0.0000,\n",
      "              0.0000,      0.0000]])\n",
      "\n",
      "tensor([[0.0000e+00, 0.0000e+00, 1.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 1.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 1.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        ...,\n",
      "        [0.0000e+00, 0.0000e+00, 1.8018e+04,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 1.8613e+04,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 1.8613e+04,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "from src.lib import PointGeometricAlgebra, TranslationGeometricAlgebra, ScalarGeometricAlgebra, PlaneGeometricAlgebra\n",
    "\n",
    "print(data.train_set[0].pos[0])\n",
    "print(PointGeometricAlgebra.fromElement(data.train_set[0].pos[0].unsqueeze(0)))\n",
    "print()\n",
    "\n",
    "print(TranslationGeometricAlgebra.fromElement(data.train_set[1].wss)[:, :8])\n",
    "print()\n",
    "\n",
    "print(ScalarGeometricAlgebra.fromElement(data.train_set[0].pressure))\n",
    "print()\n",
    "\n",
    "print(PlaneGeometricAlgebra.fromElement(data.train_set[0].face.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neverorfrog/.miniconda3/envs/gatr/lib/python3.12/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/neverorfrog/.miniconda3/envs/gatr/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "/home/neverorfrog/.miniconda3/envs/gatr/lib/python3.12/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:652: Checkpoint directory /home/neverorfrog/code/deep-learning/gatr/ckpt exists and is not empty.\n",
      "Restoring states from the checkpoint path at /home/neverorfrog/code/deep-learning/gatr/ckpt/last.ckpt\n",
      "/home/neverorfrog/.miniconda3/envs/gatr/lib/python3.12/site-packages/lightning/pytorch/utilities/model_summary/model_summary.py:461: The total number of parameters detected may be inaccurate because the model contains an instance of `UninitializedParameter`. To get an accurate number, set `self.example_input_array` in your LightningModule.\n",
      "\n",
      "  | Name   | Type       | Params | Mode \n",
      "----------------------------------------------\n",
      "0 | linear | LazyLinear | 0      | train\n",
      "----------------------------------------------\n",
      "0         Trainable params\n",
      "0         Non-trainable params\n",
      "0         Total params\n",
      "0.000     Total estimated model params size (MB)\n",
      "Restored all states from the checkpoint at /home/neverorfrog/code/deep-learning/gatr/ckpt/last.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f834025b08694e58a3a0493a50f7efc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neverorfrog/.miniconda3/envs/gatr/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/home/neverorfrog/.miniconda3/envs/gatr/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54895129a4b146cb9ef20c0c6c769d18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neverorfrog/.miniconda3/envs/gatr/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "from src.trainer import VesselTrainer\n",
    "from src.models import BaselineTransformer\n",
    "\n",
    "model = BaselineTransformer(baseline_config)\n",
    "trainer = VesselTrainer(trainer_config)\n",
    "trainer.fit(model, data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
